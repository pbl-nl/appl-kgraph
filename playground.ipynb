{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2755687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# go one folder up from \"test\"\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from graph.ingestion import FileParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: ../docs/fake-html-lang-de.html\n",
      "Parsing file: ../docs/fake-html.html\n",
      "Parsing file: ../docs/example-10k.html\n",
      "Parsing file: ../docs/fake-html-pre.html\n",
      "Parsing file: ../docs/UDHR_first_article_all.txt\n",
      "Parsing file: ../docs/fake-html-with-duplicate-elements.html\n",
      "Parsing file: ../docs/contains-pictures.docx\n",
      "Parsing file: ../docs/copy-protected.pdf\n",
      "Parsing file: ../docs/fake-html-cp1252.html\n",
      "Error parsing ../docs/fake-html-cp1252.html: 'utf-8' codec can't decode byte 0xa1 in position 135: invalid start byte\n",
      "Parsing file: ../docs/markdown-example-long-2.md\n",
      "Parsing file: ../docs/fake-html-with-footer-and-header.html\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"../docs\"  # Adjust this to your actual root directory\n",
    "fp = FileParser(root_directory)\n",
    "results = {}\n",
    "for filepath in fp.filepaths:\n",
    "    print(f\"Parsing file: {filepath}\")\n",
    "    pages, metadata =  fp.parse_file(filepath)\n",
    "    results[filepath] = {\"pages\": pages, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced 2 chunks:\n",
      "\n",
      "[0] p0–p2 (1363 chars) | overlap=0\n",
      "The development of artificial intelligence has gone through several remarkable phases, beginning with early rule-based systems and advancing toward today’s sophisticated machine learning models. One of the key breakthroughs was the recognition that statistical approaches could outperform rigidly defined instructions when dealing with uncertain or ambiguous data. This insight paved the way for natural language processing, computer vision, and speech recognition to become practical at scale. Another milestone was the shift toward deep learning, where neural networks with many layers can detect subtle patterns in images, sound, and text. These models require enormous datasets and computational resources, but the results have transformed industries from healthcare to finance. Today, organizations rely on AI not only to automate repetitive tasks but also to generate insights, predict risks, and personalize experiences for millions of users. At the same time, ethical challenges remain: how to ensure fairness, prevent bias, and preserve privacy while harnessing AI’s full potential. The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like. This is page 2 with more content that continues from the previous page. Page 3 has even more content that should be handled across page boundaries.\n",
      "---\n",
      "[1] p0–p2 (347 chars) | overlap=271\n",
      "The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like. This is page 2 with more content that continues from the previous page. Page 3 has even more content that should be handled across page boundaries. Page 3 has even more content that should be handled across page boundaries.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# go one folder up from \"test\"\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from graph.chunker import chunk_parsed_pages\n",
    "\n",
    "sample_pages = [\n",
    "    (0, \"The development of artificial intelligence has gone through several remarkable phases, beginning with early rule-based systems and advancing toward today’s sophisticated machine learning models. One of the key breakthroughs was the recognition that statistical approaches could outperform rigidly defined instructions when dealing with uncertain or ambiguous data. This insight paved the way for natural language processing, computer vision, and speech recognition to become practical at scale. Another milestone was the shift toward deep learning, where neural networks with many layers can detect subtle patterns in images, sound, and text. These models require enormous datasets and computational resources, but the results have transformed industries from healthcare to finance. Today, organizations rely on AI not only to automate repetitive tasks but also to generate insights, predict risks, and personalize experiences for millions of users. At the same time, ethical challenges remain: how to ensure fairness, prevent bias, and preserve privacy while harnessing AI’s full potential. The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like.\"),\n",
    "    (1, \"This is page 2 with more content that continues from the previous page. \" * 1), \n",
    "    (2, \"Page 3 has even more content that should be handled across page boundaries. \" * 2)\n",
    "]\n",
    "\n",
    "# Example run\n",
    "chunks = chunk_parsed_pages(sample_pages, max_chars=1400, overlap_chars=300, include_overlap_in_limit=True)\n",
    "print(f\"Produced {len(chunks)} chunks:\\n\")\n",
    "for ch in chunks:\n",
    "    print(f\"[{ch['chunk_id']}] p{ch['start_page']}–p{ch['end_page']} ({ch['char_count']} chars)\"\n",
    "            f\" | overlap={ch['overlap_chars_effective']}\")\n",
    "    print(ch[\"text\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5174fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 0,\n",
       "  'chunk_uuid': 'dbd0ea45-6d4d-4d9a-8ece-4c6cdab94edb',\n",
       "  'text': 'The development of artificial intelligence has gone through several remarkable phases, beginning with early rule-based systems and advancing toward today’s sophisticated machine learning models. One of the key breakthroughs was the recognition that statistical approaches could outperform rigidly defined instructions when dealing with uncertain or ambiguous data. This insight paved the way for natural language processing, computer vision, and speech recognition to become practical at scale. Another milestone was the shift toward deep learning, where neural networks with many layers can detect subtle patterns in images, sound, and text. These models require enormous datasets and computational resources, but the results have transformed industries from healthcare to finance. Today, organizations rely on AI not only to automate repetitive tasks but also to generate insights, predict risks, and personalize experiences for millions of users. At the same time, ethical challenges remain: how to ensure fairness, prevent bias, and preserve privacy while harnessing AI’s full potential. The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like. This is page 2 with more content that continues from the previous page. Page 3 has even more content that should be handled across page boundaries.',\n",
       "  'char_count': 1363,\n",
       "  'start_page': 0,\n",
       "  'end_page': 2,\n",
       "  'sentence_span': [(0,\n",
       "    0,\n",
       "    'The development of artificial intelligence has gone through several remarkable phases, beginning with early rule-based systems and advancing toward today’s sophisticated machine learning models.'),\n",
       "   (1,\n",
       "    0,\n",
       "    'One of the key breakthroughs was the recognition that statistical approaches could outperform rigidly defined instructions when dealing with uncertain or ambiguous data.'),\n",
       "   (2,\n",
       "    0,\n",
       "    'This insight paved the way for natural language processing, computer vision, and speech recognition to become practical at scale.'),\n",
       "   (3,\n",
       "    0,\n",
       "    'Another milestone was the shift toward deep learning, where neural networks with many layers can detect subtle patterns in images, sound, and text.'),\n",
       "   (4,\n",
       "    0,\n",
       "    'These models require enormous datasets and computational resources, but the results have transformed industries from healthcare to finance.'),\n",
       "   (5,\n",
       "    0,\n",
       "    'Today, organizations rely on AI not only to automate repetitive tasks but also to generate insights, predict risks, and personalize experiences for millions of users.'),\n",
       "   (6,\n",
       "    0,\n",
       "    'At the same time, ethical challenges remain: how to ensure fairness, prevent bias, and preserve privacy while harnessing AI’s full potential.'),\n",
       "   (7,\n",
       "    0,\n",
       "    'The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like.'),\n",
       "   (8,\n",
       "    1,\n",
       "    'This is page 2 with more content that continues from the previous page.'),\n",
       "   (9,\n",
       "    2,\n",
       "    'Page 3 has even more content that should be handled across page boundaries.')],\n",
       "  'overlap_from_previous': False,\n",
       "  'overlap_chars_effective': 0,\n",
       "  'included_new_sentence_count': 10,\n",
       "  'include_overlap_in_limit': True,\n",
       "  'max_chars_target': 1400},\n",
       " {'chunk_id': 1,\n",
       "  'chunk_uuid': 'dd2f40af-d7f0-417b-9f7a-0faf78d81a51',\n",
       "  'text': 'The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like. This is page 2 with more content that continues from the previous page. Page 3 has even more content that should be handled across page boundaries. Page 3 has even more content that should be handled across page boundaries.',\n",
       "  'char_count': 347,\n",
       "  'start_page': 0,\n",
       "  'end_page': 2,\n",
       "  'sentence_span': [(7,\n",
       "    0,\n",
       "    'The conversation now includes governments, researchers, and citizens debating what responsible innovation should look like.'),\n",
       "   (8,\n",
       "    1,\n",
       "    'This is page 2 with more content that continues from the previous page.'),\n",
       "   (9,\n",
       "    2,\n",
       "    'Page 3 has even more content that should be handled across page boundaries.'),\n",
       "   (10,\n",
       "    2,\n",
       "    'Page 3 has even more content that should be handled across page boundaries.')],\n",
       "  'overlap_from_previous': True,\n",
       "  'overlap_chars_effective': 271,\n",
       "  'included_new_sentence_count': 1,\n",
       "  'include_overlap_in_limit': True,\n",
       "  'max_chars_target': 1400}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afb60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: ../docs/copy-protected.pdf\n",
      "Produced 5 chunks:\n",
      "\n",
      "{'chunk_id': 0, 'chunk_uuid': '60e39a02-ba94-44f3-8f4c-e0a9a9d85a62', 'text': 'LayoutParser: A Uniﬁed Toolkit for Deep Learning Based Document Image Analysis Zejiang Shen1 ( ), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain Lee4, Jacob Carlson3, and Weining Li5 1 Allen Institute for AI shannons@allenai.org 2 Brown University ruochen zhang@brown.edu 3 Harvard University {melissadell,jacob carlson}@fas.harvard.edu 4 University of Washington bcgl@cs.washington.edu 5 University of Waterloo w422li@uwaterloo.ca Abstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model conﬁgurations complicate the easy reuse of im- portant innovations by a wide audience. Though there have been on-going e↵orts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions.', 'char_count': 1379, 'start_page': 0, 'end_page': 0, 'sentence_span': [{'sentence_idx': 0, 'page_number': 0, 'text': 'LayoutParser: A Uniﬁed Toolkit for Deep Learning Based Document Image Analysis Zejiang Shen1 ( ), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain Lee4, Jacob Carlson3, and Weining Li5'}, {'sentence_idx': 1, 'page_number': 0, 'text': '1 Allen Institute for AI shannons@allenai.org 2 Brown University ruochen zhang@brown.edu 3 Harvard University {melissadell,jacob carlson}@fas.harvard.edu'}, {'sentence_idx': 2, 'page_number': 0, 'text': '4 University of Washington bcgl@cs.washington.edu'}, {'sentence_idx': 3, 'page_number': 0, 'text': '5 University of Waterloo w422li@uwaterloo.ca Abstract.'}, {'sentence_idx': 4, 'page_number': 0, 'text': 'Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks.'}, {'sentence_idx': 5, 'page_number': 0, 'text': 'Ideally, research outcomes could be easily deployed in production and extended for further investigation.'}, {'sentence_idx': 6, 'page_number': 0, 'text': 'However, various factors like loosely organized codebases and sophisticated model conﬁgurations complicate the easy reuse of im- portant innovations by a wide audience.'}, {'sentence_idx': 7, 'page_number': 0, 'text': 'Though there have been on-going e↵orts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA.'}, {'sentence_idx': 8, 'page_number': 0, 'text': 'This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities.'}, {'sentence_idx': 9, 'page_number': 0, 'text': 'This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions.'}], 'overlap_from_previous': False, 'overlap_chars_effective': 0, 'included_new_sentence_count': 10, 'include_overlap_in_limit': True, 'max_chars_target': 1400}\n",
      "---\n",
      "{'chunk_id': 1, 'chunk_uuid': '0b22e89a-edea-4206-a13a-7c63aa57cab5', 'text': 'This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout de- tection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases. The library is publicly available at https://layout-parser.github.io. Keywords: Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit. 1 Introduction Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classiﬁcation [11, arXiv:2103.15348v2 [cs.CV] 21 Jun 2021 2 Z. Shen et al. 37], layout detection [38, 22], table detection [26], and scene text detection [4].', 'char_count': 1299, 'start_page': 0, 'end_page': 1, 'sentence_span': [{'sentence_idx': 8, 'page_number': 0, 'text': 'This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities.'}, {'sentence_idx': 9, 'page_number': 0, 'text': 'This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions.'}, {'sentence_idx': 10, 'page_number': 0, 'text': 'The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout de- tection, character recognition, and many other document processing tasks.'}, {'sentence_idx': 11, 'page_number': 0, 'text': 'To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation pipelines.'}, {'sentence_idx': 12, 'page_number': 0, 'text': 'We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases.'}, {'sentence_idx': 13, 'page_number': 0, 'text': 'The library is publicly available at https://layout-parser.github.io.'}, {'sentence_idx': 14, 'page_number': 0, 'text': 'Keywords: Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit.'}, {'sentence_idx': 15, 'page_number': 0, 'text': '1 Introduction Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classiﬁcation [11, arXiv:2103.15348v2 [cs.CV] 21 Jun 2021'}, {'sentence_idx': 16, 'page_number': 1, 'text': '2 Z.'}, {'sentence_idx': 17, 'page_number': 1, 'text': 'Shen et al.'}, {'sentence_idx': 18, 'page_number': 1, 'text': '37], layout detection [38, 22], table detection [26], and scene text detection [4].'}], 'overlap_from_previous': True, 'overlap_chars_effective': 293, 'included_new_sentence_count': 9, 'include_overlap_in_limit': True, 'max_chars_target': 1400}\n",
      "---\n",
      "{'chunk_id': 2, 'chunk_uuid': 'ca59171e-f894-4247-bab7-8ac73c55ab75', 'text': '2 Z. Shen et al. 37], layout detection [38, 22], table detection [26], and scene text detection [4]. A generalized learning-based framework dramatically reduces the need for the manual speciﬁcation of complicated rules, which is the status quo with traditional methods. DL has the potential to transform DIA pipelines and beneﬁt a broad spectrum of large-scale document digitization projects. However, there are several practical diﬃculties for taking advantages of re- cent advances in DL-based methods: 1) DL models are notoriously convoluted for reuse and extension. Existing models are developed using distinct frame- works like TensorFlow [1] or PyTorch [24], and the high-level parameters can be obfuscated by implementation details [8]. It can be a time-consuming and frustrating experience to debug, reproduce, and adapt existing models for DIA, and many researchers who would beneﬁt the most from using these methods lack the technical background to implement them from scratch. 2) Document images contain diverse and disparate patterns across domains, and customized training is often required to achieve a desirable detection accuracy. Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models. 3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs.', 'char_count': 1386, 'start_page': 1, 'end_page': 1, 'sentence_span': [{'sentence_idx': 16, 'page_number': 1, 'text': '2 Z.'}, {'sentence_idx': 17, 'page_number': 1, 'text': 'Shen et al.'}, {'sentence_idx': 18, 'page_number': 1, 'text': '37], layout detection [38, 22], table detection [26], and scene text detection [4].'}, {'sentence_idx': 19, 'page_number': 1, 'text': 'A generalized learning-based framework dramatically reduces the need for the manual speciﬁcation of complicated rules, which is the status quo with traditional methods.'}, {'sentence_idx': 20, 'page_number': 1, 'text': 'DL has the potential to transform DIA pipelines and beneﬁt a broad spectrum of large-scale document digitization projects.'}, {'sentence_idx': 21, 'page_number': 1, 'text': 'However, there are several practical diﬃculties for taking advantages of re- cent advances in DL-based methods: 1) DL models are notoriously convoluted for reuse and extension.'}, {'sentence_idx': 22, 'page_number': 1, 'text': 'Existing models are developed using distinct frame- works like TensorFlow [1] or PyTorch [24], and the high-level parameters can be obfuscated by implementation details [8].'}, {'sentence_idx': 23, 'page_number': 1, 'text': 'It can be a time-consuming and frustrating experience to debug, reproduce, and adapt existing models for DIA, and many researchers who would beneﬁt the most from using these methods lack the technical background to implement them from scratch.'}, {'sentence_idx': 24, 'page_number': 1, 'text': '2) Document images contain diverse and disparate patterns across domains, and customized training is often required to achieve a desirable detection accuracy.'}, {'sentence_idx': 25, 'page_number': 1, 'text': 'Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models.'}, {'sentence_idx': 26, 'page_number': 1, 'text': '3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs.'}], 'overlap_from_previous': True, 'overlap_chars_effective': 100, 'included_new_sentence_count': 8, 'include_overlap_in_limit': True, 'max_chars_target': 1400}\n",
      "---\n",
      "{'chunk_id': 3, 'chunk_uuid': '53ec5125-3368-4fc8-88d3-39fcfde48c26', 'text': 'Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models. 3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs. Often research teams use DL models and then perform further document analyses in separate processes, and these pipelines are not documented in any central location (and often not documented at all). This makes it diﬃcult for research teams to learn about how full pipelines are implemented and leads them to invest signiﬁcant resources in reinventing the DIA wheel. LayoutParser provides a uniﬁed toolkit to support DL-based document image analysis and processing. To address the aforementioned challenges, LayoutParser is built with the following components: 1. An o↵-the-shelf toolkit for applying DL models for layout detection, character recognition, and other DIA tasks (Section 3) 2. A rich repository of pre-trained neural network models (Model Zoo) that underlies the o↵-the-shelf usage 3. Comprehensive tools for eﬃcient document image data annotation and model tuning to support di↵erent levels of customization 4.', 'char_count': 1164, 'start_page': 1, 'end_page': 1, 'sentence_span': [{'sentence_idx': 25, 'page_number': 1, 'text': 'Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models.'}, {'sentence_idx': 26, 'page_number': 1, 'text': '3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs.'}, {'sentence_idx': 27, 'page_number': 1, 'text': 'Often research teams use DL models and then perform further document analyses in separate processes, and these pipelines are not documented in any central location (and often not documented at all).'}, {'sentence_idx': 28, 'page_number': 1, 'text': 'This makes it diﬃcult for research teams to learn about how full pipelines are implemented and leads them to invest signiﬁcant resources in reinventing the DIA wheel.'}, {'sentence_idx': 29, 'page_number': 1, 'text': 'LayoutParser provides a uniﬁed toolkit to support DL-based document image analysis and processing.'}, {'sentence_idx': 30, 'page_number': 1, 'text': 'To address the aforementioned challenges, LayoutParser is built with the following components:'}, {'sentence_idx': 31, 'page_number': 1, 'text': '1.'}, {'sentence_idx': 32, 'page_number': 1, 'text': 'An o↵-the-shelf toolkit for applying DL models for layout detection, character recognition, and other DIA tasks (Section 3) 2.'}, {'sentence_idx': 33, 'page_number': 1, 'text': 'A rich repository of pre-trained neural network models (Model Zoo) that underlies the o↵-the-shelf usage 3.'}, {'sentence_idx': 34, 'page_number': 1, 'text': 'Comprehensive tools for eﬃcient document image data annotation and model tuning to support di↵erent levels of customization 4.'}], 'overlap_from_previous': True, 'overlap_chars_effective': 239, 'included_new_sentence_count': 8, 'include_overlap_in_limit': True, 'max_chars_target': 1400}\n",
      "---\n",
      "{'chunk_id': 4, 'chunk_uuid': '1062b93a-31f7-40b9-83a9-821060b4075a', 'text': 'A rich repository of pre-trained neural network models (Model Zoo) that underlies the o↵-the-shelf usage 3. Comprehensive tools for eﬃcient document image data annotation and model tuning to support di↵erent levels of customization 4. A DL model hub and community platform for the easy sharing, distribu- tion, and discussion of DIA models and pipelines, to promote reusability, reproducibility, and extensibility (Section 4) The library implements simple and intuitive Python APIs without sacriﬁcing generalizability and versatility, and can be easily installed via pip. Its convenient functions for handling document image data can be seamlessly integrated with existing DIA pipelines. With detailed documentations and carefully curated tutorials, we hope this tool will beneﬁt a variety of end-users, and will lead to advances in applications in both industry and academic research. LayoutParser is well aligned with recent e↵orts for improving DL model reusability in other disciplines like natural language processing [8, 34] and com- puter vision [35], but with a focus on unique challenges in DIA. We show LayoutParser can be applied in sophisticated and large-scale digitization projects', 'char_count': 1195, 'start_page': 1, 'end_page': 1, 'sentence_span': [{'sentence_idx': 33, 'page_number': 1, 'text': 'A rich repository of pre-trained neural network models (Model Zoo) that underlies the o↵-the-shelf usage 3.'}, {'sentence_idx': 34, 'page_number': 1, 'text': 'Comprehensive tools for eﬃcient document image data annotation and model tuning to support di↵erent levels of customization 4.'}, {'sentence_idx': 35, 'page_number': 1, 'text': 'A DL model hub and community platform for the easy sharing, distribu- tion, and discussion of DIA models and pipelines, to promote reusability, reproducibility, and extensibility (Section 4) The library implements simple and intuitive Python APIs without sacriﬁcing generalizability and versatility, and can be easily installed via pip.'}, {'sentence_idx': 36, 'page_number': 1, 'text': 'Its convenient functions for handling document image data can be seamlessly integrated with existing DIA pipelines.'}, {'sentence_idx': 37, 'page_number': 1, 'text': 'With detailed documentations and carefully curated tutorials, we hope this tool will beneﬁt a variety of end-users, and will lead to advances in applications in both industry and academic research.'}, {'sentence_idx': 38, 'page_number': 1, 'text': 'LayoutParser is well aligned with recent e↵orts for improving DL model reusability in other disciplines like natural language processing [8, 34] and com- puter vision [35], but with a focus on unique challenges in DIA.'}, {'sentence_idx': 39, 'page_number': 1, 'text': 'We show LayoutParser can be applied in sophisticated and large-scale digitization projects'}], 'overlap_from_previous': True, 'overlap_chars_effective': 234, 'included_new_sentence_count': 5, 'include_overlap_in_limit': True, 'max_chars_target': 1400}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# go one folder up from \"test\"\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from graph.chunker import chunk_parsed_pages\n",
    "from graph.fileparser import FileParser\n",
    "\n",
    "root_directory = \"../docs\"  # Adjust this to your actual root directory\n",
    "fp = FileParser(root_directory)\n",
    "results = {}\n",
    "for filepath in fp.filepaths:\n",
    "    if filepath.endswith(\".pdf\"):\n",
    "        print(f\"Parsing file: {filepath}\")\n",
    "        pages, metadata =  fp.parse_file(filepath)\n",
    "        results[filepath] = {\"pages\": pages, \"metadata\": metadata}\n",
    "        chunks = chunk_parsed_pages(pages, max_chars=1400, overlap_chars=300, include_overlap_in_limit=True)\n",
    "        print(f\"Produced {len(chunks)} chunks:\\n\")\n",
    "        for ch in chunks:\n",
    "            print(ch)\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83830c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake-html-lang-de.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.filepaths[0].split(os.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8558a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    # AI Transformers Research Paper - Internal relationships\n",
    "    {\n",
    "        \"source_name\": \"Transformer Architecture\",\n",
    "        \"target_name\": \"Self-Attention Mechanism\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Transformer architecture was introduced by Vaswani et al. in 2017\",\n",
    "        \"keywords\": \"introduction, research, authorship\",\n",
    "        \"source_id\": \"ce3e73a2-7d1a-4111-b374-c4388c0b966d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Transformer Architecture\",\n",
    "        \"u_target_name\": \"Vaswani et al.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Self-Attention Mechanism\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.95,\n",
    "        \"description\": \"Self-attention mechanism is the core component of transformer architecture\",\n",
    "        \"keywords\": \"component, core, architecture\",\n",
    "        \"source_id\": \"91c96a29-dc84-45a8-8e09-15645c8a8c02\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Self-Attention Mechanism\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Multi-Head Attention\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Multi-head attention is a key component of transformer architecture\",\n",
    "        \"keywords\": \"component, attention, multiple\",\n",
    "        \"source_id\": \"bb95f0a9-bc63-4962-bce6-e9966c7d2c92\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Multi-Head Attention\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Multi-Head Attention\",\n",
    "        \"target_name\": \"Self-Attention Mechanism\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"Multi-head attention extends self-attention mechanism with multiple attention heads\",\n",
    "        \"keywords\": \"extension, multiple, attention\",\n",
    "        \"source_id\": \"bb95f0a9-bc63-4962-bce6-e9966c7d2c92\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Multi-Head Attention\",\n",
    "        \"u_target_name\": \"Self-Attention Mechanism\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Positional Encoding\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"Positional encoding preserves sequence order in transformer architecture\",\n",
    "        \"keywords\": \"sequence, order, position\",\n",
    "        \"source_id\": \"bb95f0a9-bc63-4962-bce6-e9966c7d2c92\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Positional Encoding\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Recurrent Neural Networks\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.7,\n",
    "        \"description\": \"RNNs are contrasted with transformers as traditional sequential processing approach\",\n",
    "        \"keywords\": \"contrast, traditional, sequential\",\n",
    "        \"source_id\": \"91c96a29-dc84-45a8-8e09-15645c8a8c02\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Recurrent Neural Networks\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Long-Range Dependencies\",\n",
    "        \"target_name\": \"Recurrent Neural Networks\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"RNNs have limitations in capturing long-range dependencies\",\n",
    "        \"keywords\": \"limitation, capture, sequential\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Long-Range Dependencies\",\n",
    "        \"u_target_name\": \"Recurrent Neural Networks\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Long-Range Dependencies\",\n",
    "        \"target_name\": \"Self-Attention Mechanism\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Self-attention mechanism efficiently captures long-range dependencies\",\n",
    "        \"keywords\": \"efficient, capture, attention\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Long-Range Dependencies\",\n",
    "        \"u_target_name\": \"Self-Attention Mechanism\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Natural Language Processing\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Transformers are foundational for state-of-the-art NLP models\",\n",
    "        \"keywords\": \"foundation, state-of-the-art, application\",\n",
    "        \"source_id\": \"4ae9ba1d-ea8b-4d1c-b768-425d767576de\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Natural Language Processing\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Computer Vision\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"Transformers demonstrate versatility and performance in computer vision\",\n",
    "        \"keywords\": \"versatility, performance, application\",\n",
    "        \"source_id\": \"4ae9ba1d-ea8b-4d1c-b768-425d767576de\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Computer Vision\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Machine Learning Revolution\",\n",
    "        \"target_name\": \"Transformer Architecture\",\n",
    "        \"weight\": 0.95,\n",
    "        \"description\": \"Transformer architecture drives the machine learning revolution\",\n",
    "        \"keywords\": \"revolution, transformation, paradigm\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Machine Learning Revolution\",\n",
    "        \"u_target_name\": \"Transformer Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Machine Learning Revolution\",\n",
    "        \"target_name\": \"Self-Attention Mechanism\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"Self-attention mechanism is a key driver of the ML revolution\",\n",
    "        \"keywords\": \"driver, attention, breakthrough\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\",\n",
    "        \"u_source_name\": \"Machine Learning Revolution\",\n",
    "        \"u_target_name\": \"Self-Attention Mechanism\"\n",
    "    },\n",
    "\n",
    "    # Weekly Team Meeting - Internal relationships\n",
    "    {\n",
    "        \"source_name\": \"Sarah Johnson\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Sarah Johnson is the Product Manager in the development team\",\n",
    "        \"keywords\": \"product manager, team member, leadership\",\n",
    "        \"source_id\": \"b95c346b-1802-41cd-96de-d8a5826fa200\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Development Team\",\n",
    "        \"u_target_name\": \"Sarah Johnson\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Mike Chen\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Mike Chen is the Lead Developer in the development team\",\n",
    "        \"keywords\": \"lead developer, team member, technical\",\n",
    "        \"source_id\": \"46d45855-4286-48b9-93e2-b538905f0222\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Development Team\",\n",
    "        \"u_target_name\": \"Mike Chen\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Sprint Review\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"Development team conducted sprint review of completed work\",\n",
    "        \"keywords\": \"review, process, completion\",\n",
    "        \"source_id\": \"750a0cb7-d488-4226-a45c-9a56811162d7\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Development Team\",\n",
    "        \"u_target_name\": \"Sprint Review\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Performance Improvements\",\n",
    "        \"target_name\": \"Sprint Review\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Performance improvements were successfully implemented during the sprint\",\n",
    "        \"keywords\": \"implementation, success, deliverable\",\n",
    "        \"source_id\": \"750a0cb7-d488-4226-a45c-9a56811162d7\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Performance Improvements\",\n",
    "        \"u_target_name\": \"Sprint Review\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Database Migration\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"Database migration is a critical task for the development team\",\n",
    "        \"keywords\": \"critical, blocker, infrastructure\",\n",
    "        \"source_id\": \"f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Database Migration\",\n",
    "        \"u_target_name\": \"Development Team\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Third-Party API Integration\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"Third-party API integration requires development work and security review\",\n",
    "        \"keywords\": \"integration, security, review\",\n",
    "        \"source_id\": \"f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Development Team\",\n",
    "        \"u_target_name\": \"Third-Party API Integration\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"User Authentication Improvements\",\n",
    "        \"target_name\": \"Development Team\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"User authentication improvements are upcoming focus for the development team\",\n",
    "        \"keywords\": \"security, priority, focus\",\n",
    "        \"source_id\": \"3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Development Team\",\n",
    "        \"u_target_name\": \"User Authentication Improvements\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Q1 Security Audit\",\n",
    "        \"target_name\": \"User Authentication Improvements\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"User authentication improvements are needed for Q1 security audit preparation\",\n",
    "        \"keywords\": \"security, audit, preparation\",\n",
    "        \"source_id\": \"3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"Q1 Security Audit\",\n",
    "        \"u_target_name\": \"User Authentication Improvements\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"API Documentation\",\n",
    "        \"target_name\": \"Mike Chen\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Mike Chen is responsible for completing API documentation by Wednesday\",\n",
    "        \"keywords\": \"responsibility, deadline, documentation\",\n",
    "        \"source_id\": \"46d45855-4286-48b9-93e2-b538905f0222\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"API Documentation\",\n",
    "        \"u_target_name\": \"Mike Chen\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"API Documentation\",\n",
    "        \"target_name\": \"Third-Party API Integration\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"API documentation is related to third-party API integration work\",\n",
    "        \"keywords\": \"documentation, integration, technical\",\n",
    "        \"source_id\": \"46d45855-4286-48b9-93e2-b538905f0222\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\",\n",
    "        \"u_source_name\": \"API Documentation\",\n",
    "        \"u_target_name\": \"Third-Party API Integration\"\n",
    "    },\n",
    "\n",
    "    # Grandma's Recipe Collection - Internal relationships\n",
    "    {\n",
    "        \"source_name\": \"Chocolate Chip Cookies\",\n",
    "        \"target_name\": \"Baking Ingredients\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Chocolate chip cookies recipe requires specific baking ingredients\",\n",
    "        \"keywords\": \"recipe, ingredients, baking\",\n",
    "        \"source_id\": \"dce983d4-888e-4c83-a8d0-fadd7404058b\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Baking Ingredients\",\n",
    "        \"u_target_name\": \"Chocolate Chip Cookies\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Cookie Baking Process\",\n",
    "        \"target_name\": \"Chocolate Chip Cookies\",\n",
    "        \"weight\": 0.95,\n",
    "        \"description\": \"Cookie baking process describes how to make chocolate chip cookies\",\n",
    "        \"keywords\": \"process, procedure, instructions\",\n",
    "        \"source_id\": \"30b5998f-64e0-4dc4-a995-ba49279ba2a8\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chocolate Chip Cookies\",\n",
    "        \"u_target_name\": \"Cookie Baking Process\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Cookie Baking Process\",\n",
    "        \"target_name\": \"Oven Temperature\",\n",
    "        \"weight\": 0.85,\n",
    "        \"description\": \"Cookie baking process requires specific oven temperature of 375°F\",\n",
    "        \"keywords\": \"temperature, baking, requirement\",\n",
    "        \"source_id\": \"30b5998f-64e0-4dc4-a995-ba49279ba2a8\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Cookie Baking Process\",\n",
    "        \"u_target_name\": \"Oven Temperature\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Chicken Soup\",\n",
    "        \"target_name\": \"Soup Vegetables\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Chicken soup recipe uses fresh vegetables for flavor and nutrition\",\n",
    "        \"keywords\": \"ingredients, vegetables, nutrition\",\n",
    "        \"source_id\": \"83655f0c-c6f9-4572-aec3-8a4103d67199\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Soup\",\n",
    "        \"u_target_name\": \"Soup Vegetables\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Soup Preparation Method\",\n",
    "        \"target_name\": \"Chicken Soup\",\n",
    "        \"weight\": 0.95,\n",
    "        \"description\": \"Soup preparation method describes how to make chicken soup\",\n",
    "        \"keywords\": \"method, preparation, instructions\",\n",
    "        \"source_id\": \"70949b44-8d6c-4171-9590-0f7d58f60ea4\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Soup\",\n",
    "        \"u_target_name\": \"Soup Preparation Method\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Chicken Broth\",\n",
    "        \"target_name\": \"Soup Preparation Method\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Chicken broth is created through the soup preparation method\",\n",
    "        \"keywords\": \"broth, foundation, simmering\",\n",
    "        \"source_id\": \"70949b44-8d6c-4171-9590-0f7d58f60ea4\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Broth\",\n",
    "        \"u_target_name\": \"Soup Preparation Method\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Chicken Broth\",\n",
    "        \"target_name\": \"Chicken Soup\",\n",
    "        \"weight\": 0.95,\n",
    "        \"description\": \"Chicken broth forms the foundation of chicken soup\",\n",
    "        \"keywords\": \"foundation, base, soup\",\n",
    "        \"source_id\": \"70949b44-8d6c-4171-9590-0f7d58f60ea4\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Broth\",\n",
    "        \"u_target_name\": \"Chicken Soup\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Family Recipe Tradition\",\n",
    "        \"target_name\": \"Chocolate Chip Cookies\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"Chocolate chip cookies are part of three-generation family recipe tradition\",\n",
    "        \"keywords\": \"tradition, family, heritage\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chocolate Chip Cookies\",\n",
    "        \"u_target_name\": \"Family Recipe Tradition\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Family Recipe Tradition\",\n",
    "        \"target_name\": \"Chicken Soup\",\n",
    "        \"weight\": 0.8,\n",
    "        \"description\": \"Chicken soup is part of three-generation family recipe tradition\",\n",
    "        \"keywords\": \"tradition, family, heritage\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Soup\",\n",
    "        \"u_target_name\": \"Family Recipe Tradition\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Cooking Secrets\",\n",
    "        \"target_name\": \"Family Recipe Tradition\",\n",
    "        \"weight\": 0.9,\n",
    "        \"description\": \"Cooking secrets are part of the family recipe tradition knowledge\",\n",
    "        \"keywords\": \"secrets, knowledge, tradition\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Cooking Secrets\",\n",
    "        \"u_target_name\": \"Family Recipe Tradition\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Cooking Secrets\",\n",
    "        \"target_name\": \"Cookie Baking Process\",\n",
    "        \"weight\": 0.7,\n",
    "        \"description\": \"Cooking secrets include tips for cookie baking like using room temperature butter\",\n",
    "        \"keywords\": \"tips, butter, technique\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Cookie Baking Process\",\n",
    "        \"u_target_name\": \"Cooking Secrets\"\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Cooking Secrets\",\n",
    "        \"target_name\": \"Chicken Broth\",\n",
    "        \"weight\": 0.7,\n",
    "        \"description\": \"Cooking secrets include using homemade broth for better soup\",\n",
    "        \"keywords\": \"homemade, quality, technique\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\",\n",
    "        \"u_source_name\": \"Chicken Broth\",\n",
    "        \"u_target_name\": \"Cooking Secrets\"\n",
    "    }\n",
    "]\n",
    "\n",
    "nodes = [\n",
    "    # Document 1: AI Transformers Research Paper - Chunk 1\n",
    "    {\n",
    "        \"name\": \"Transformer Architecture\",\n",
    "        \"type\": \"CONCEPT\",\n",
    "        \"description\": \"Revolutionary AI model architecture introduced by Vaswani et al. in 2017 with attention mechanism and parallel processing capabilities\",\n",
    "        \"source_id\": \"ce3e7-7d1a-4111-b374-c4388c0b966d\",\n",
    "        \"filepath\": \"ai_transformersverview.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Transformer Architecture\",\n",
    "        \"type\": \"TECHNIQUE\",\n",
    "        \"description\": \"Research team that introduced the transformer model in 2017, revolutionizing machine learning\",\n",
    "        \"source_id\": \"ce3e73a2-7d1a-4111-b374-c4388c0b966d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "\n",
    "    # Document 1: AI Transformers Research Paper - Chunk 2\n",
    "    {\n",
    "        \"name\": \"Transformer Architecture\",\n",
    "        \"type\": \"TECHNIQUE\",\n",
    "        \"description\": \"Core component of transformer architecture that allows models to focus on relevant parts of input sequence regardless of position\",\n",
    "        \"source_id\": \"91c96a29-dc84-45a8-8e09-15645c8a8c02\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Recurrent Neural Networks\",\n",
    "        \"type\": \"CONCEPT\",\n",
    "        \"description\": \"Traditional neural network architecture that processes sequences sequentially, limiting long-range dependency capture\",\n",
    "        \"source_id\": \"91c96a29-dc84-45a8-8e09-15645c8a8c02\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "\n",
    "    # Document 1: AI Transformers Research Paper - Chunk 3\n",
    "    {\n",
    "        \"name\": \"Multi-Head Attention\",\n",
    "        \"type\": \"TECHNIQUE\",\n",
    "        \"description\": \"Transformer component that enables diverse representation learning through multiple attention mechanisms\",\n",
    "        \"source_id\": \"bb95f0a9-bc63-4962-bce6-e9966c7d2c92\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Positional Encoding\",\n",
    "        \"type\": \"TECHNIQUE\",\n",
    "        \"description\": \"Method used in transformers to preserve sequence order information during parallel processing\",\n",
    "        \"source_id\": \"bb95f0a9-bc63-4962-bce6-e9966c7d2c92\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "\n",
    "    # Document 1: AI Transformers Research Paper - Chunk 4\n",
    "    {\n",
    "        \"name\": \"Natural Language Processing\",\n",
    "        \"type\": \"DOMAIN\",\n",
    "        \"description\": \"Field of AI where transformers have become the foundation for state-of-the-art models\",\n",
    "        \"source_id\": \"4ae9ba1d-ea8b-4d1c-b768-425d767576de\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Computer Vision\",\n",
    "        \"type\": \"DOMAIN\",\n",
    "        \"description\": \"AI domain where transformers demonstrate remarkable versatility and performance improvements\",\n",
    "        \"source_id\": \"4ae9ba1d-ea8b-4d1c-b768-425d767576de\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "\n",
    "    # Document 1: AI Transformers Research Paper - Chunk 5\n",
    "    {\n",
    "        \"name\": \"Machine Learning Revolution\",\n",
    "        \"type\": \"CONCEPT\",\n",
    "        \"description\": \"Transformation in ML field driven by transformer models through attention mechanisms and parallel processing\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Long-Range Dependencies\",\n",
    "        \"type\": \"CONCEPT\",\n",
    "        \"description\": \"Relationships between distant elements in sequences that transformers can capture more efficiently than RNNs\",\n",
    "        \"source_id\": \"a8ce29a9-1f26-435d-8d1f-dfd96368af8d\",\n",
    "        \"filepath\": \"ai_transformers_overview.pdf\"\n",
    "    },\n",
    "\n",
    "    # Document 2: Weekly Team Meeting Notes - Chunk 1\n",
    "    {\n",
    "        \"name\": \"Sarah Johnson\",\n",
    "        \"type\": \"PERSON\",\n",
    "        \"description\": \"Product Manager attending the weekly team meeting on January 15, 2025\",\n",
    "        \"source_id\": \"b95c346b-1802-41cd-96de-d8a5826fa200\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Development Team\",\n",
    "        \"type\": \"ORGANIZATION\",\n",
    "        \"description\": \"Cross-functional team including Product Manager, Developer, UX Designer, Data Scientist, and QA Engineer\",\n",
    "        \"source_id\": \"b95c346b-1802-41cd-96de-d8a5826fa200\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "\n",
    "    # Document 2: Weekly Team Meeting Notes - Chunk 2\n",
    "    {\n",
    "        \"name\": \"Sprint Review\",\n",
    "        \"type\": \"PROCESS\",\n",
    "        \"description\": \"Team completed 8 out of 10 planned user stories with successful performance improvements implementation\",\n",
    "        \"source_id\": \"750a0cb7-d488-4226-a45c-9a56811162d7\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Performance Improvements\",\n",
    "        \"type\": \"DELIVERABLE\",\n",
    "        \"description\": \"Successfully implemented enhancements to system performance during the current sprint\",\n",
    "        \"source_id\": \"750a0cb7-d488-4226-a45c-9a56811162d7\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "\n",
    "    # Document 2: Weekly Team Meeting Notes - Chunk 3\n",
    "    {\n",
    "        \"name\": \"Database Migration\",\n",
    "        \"type\": \"TASK\",\n",
    "        \"description\": \"Critical project blocker delayed pending infrastructure team approval\",\n",
    "        \"source_id\": \"f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Third-Party API Integration\",\n",
    "        \"type\": \"TASK\",\n",
    "        \"description\": \"Development work requiring security review before implementation can proceed\",\n",
    "        \"source_id\": \"f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "\n",
    "    # Document 2: Weekly Team Meeting Notes - Chunk 4\n",
    "    {\n",
    "        \"name\": \"User Authentication Improvements\",\n",
    "        \"type\": \"PRIORITY\",\n",
    "        \"description\": \"Upcoming focus area for the development team to enhance system security\",\n",
    "        \"source_id\": \"3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Q1 Security Audit\",\n",
    "        \"type\": \"MILESTONE\",\n",
    "        \"description\": \"Upcoming security assessment that the team needs to prepare for\",\n",
    "        \"source_id\": \"3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "\n",
    "    # Document 2: Weekly Team Meeting Notes - Chunk 5\n",
    "    {\n",
    "        \"name\": \"Mike Chen\",\n",
    "        \"type\": \"PERSON\",\n",
    "        \"description\": \"Lead Developer responsible for completing API documentation by Wednesday\",\n",
    "        \"source_id\": \"46d45855-4286-48b9-93e2-b538905f0222\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"API Documentation\",\n",
    "        \"type\": \"DELIVERABLE\",\n",
    "        \"description\": \"Technical documentation task assigned to Mike Chen with Wednesday deadline\",\n",
    "        \"source_id\": \"46d45855-4286-48b9-93e2-b538905f0222\",\n",
    "        \"filepath\": \"weekly_team_meeting_2025_01_15.txt\"\n",
    "    },\n",
    "\n",
    "    # Document 3: Grandma's Recipe Collection - Chunk 1\n",
    "    {\n",
    "        \"name\": \"Chocolate Chip Cookies\",\n",
    "        \"type\": \"RECIPE\",\n",
    "        \"description\": \"Classic cookie recipe requiring all-purpose flour, butter, sugars, eggs, vanilla, and chocolate chips\",\n",
    "        \"source_id\": \"dce983d4-888e-4c83-a8d0-fadd7404058b\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Baking Ingredients\",\n",
    "        \"type\": \"CATEGORY\",\n",
    "        \"description\": \"Essential ingredients for cookie making including flour, baking soda, butter, sugars, and chocolate chips\",\n",
    "        \"source_id\": \"dce983d4-888e-4c83-a8d0-fadd7404058b\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "\n",
    "    # Document 3: Grandma's Recipe Collection - Chunk 2\n",
    "    {\n",
    "        \"name\": \"Cookie Baking Process\",\n",
    "        \"type\": \"PROCEDURE\",\n",
    "        \"description\": \"Step-by-step instructions for making cookies from mixing ingredients to baking at 375°F for 9-11 minutes\",\n",
    "        \"source_id\": \"30b5998f-64e0-4dc4-a995-ba49279ba2a8\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Oven Temperature\",\n",
    "        \"type\": \"PARAMETER\",\n",
    "        \"description\": \"Specific baking temperature of 375°F (190°C) required for proper cookie preparation\",\n",
    "        \"source_id\": \"30b5998f-64e0-4dc4-a995-ba49279ba2a8\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "\n",
    "    # Document 3: Grandma's Recipe Collection - Chunk 3\n",
    "    {\n",
    "        \"name\": \"Chicken Soup\",\n",
    "        \"type\": \"RECIPE\",\n",
    "        \"description\": \"Homemade soup recipe using whole chicken, vegetables, and egg noodles in a hearty broth\",\n",
    "        \"source_id\": \"83655f0c-c6f9-4572-aec3-8a4103d67199\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Soup Vegetables\",\n",
    "        \"type\": \"INGREDIENT_GROUP\",\n",
    "        \"description\": \"Fresh vegetables for soup including carrots, celery, onion, and parsley for flavor and nutrition\",\n",
    "        \"source_id\": \"83655f0c-c6f9-4572-aec3-8a4103d67199\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "\n",
    "    # Document 3: Grandma's Recipe Collection - Chunk 4\n",
    "    {\n",
    "        \"name\": \"Soup Preparation Method\",\n",
    "        \"type\": \"PROCEDURE\",\n",
    "        \"description\": \"Complete process from simmering whole chicken to adding vegetables, noodles, and seasoning\",\n",
    "        \"source_id\": \"70949b44-8d6c-4171-9590-0f7d58f60ea4\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Chicken Broth\",\n",
    "        \"type\": \"BASE_INGREDIENT\",\n",
    "        \"description\": \"Homemade broth created by simmering whole chicken for 1 hour, forming the soup's foundation\",\n",
    "        \"source_id\": \"70949b44-8d6c-4171-9590-0f7d58f60ea4\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "\n",
    "    # Document 3: Grandma's Recipe Collection - Chunk 5\n",
    "    {\n",
    "        \"name\": \"Family Recipe Tradition\",\n",
    "        \"type\": \"CONCEPT\",\n",
    "        \"description\": \"Three-generation tradition of passing down cooking knowledge and recipe secrets\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Cooking Secrets\",\n",
    "        \"type\": \"KNOWLEDGE\",\n",
    "        \"description\": \"Traditional cooking tips including using room temperature butter for cookies and homemade broth for soup\",\n",
    "        \"source_id\": \"8de720dd-3311-475d-9c5b-bcabd28a3c1e\",\n",
    "        \"filepath\": \"grandmas_recipes.md\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d656ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from graph.storage import Storage\n",
    "from graph.storage import StoragePaths\n",
    "from typing import List, Dict, Any\n",
    "DELIMITER = \"||\"\n",
    "\n",
    "\n",
    "def group_nodes(storage: Storage, nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    grouped = defaultdict(list)\n",
    "    for n in nodes:\n",
    "        grouped[n[\"name\"]].append({\n",
    "            \"type\": n[\"type\"],\n",
    "            \"description\": n[\"description\"],\n",
    "            \"source_id\": n[\"source_id\"],\n",
    "            \"filepath\": n[\"filepath\"],\n",
    "        })\n",
    "    # append existing nodes from storage\n",
    "    for name in list(grouped.keys()):\n",
    "        existing = storage.get_node(name=name)\n",
    "        if existing:\n",
    "            grouped[name].append({\n",
    "                \"type\": existing.get(\"type\", \"\"),\n",
    "                \"description\": existing.get(\"description\", \"\"),\n",
    "                \"source_id\": existing.get(\"source_id\", \"\"),\n",
    "                \"filepath\": existing.get(\"filepath\", \"\"),\n",
    "                })\n",
    "\n",
    "    for name in list(grouped.keys()):\n",
    "        attrs = grouped[name]\n",
    "        from collections import Counter\n",
    "        # Choose the most common type if multiple\n",
    "        most_common_type, _ = Counter([a[\"type\"] for a in attrs]).most_common(1)[0]\n",
    "        t = most_common_type\n",
    "        descriptions = DELIMITER.join({d.strip() for a in attrs if a.get(\"description\") for d in a.get(\"description\").split(DELIMITER)})\n",
    "        source_ids = DELIMITER.join({s.strip() for a in attrs if a.get(\"source_id\") for s in a.get(\"source_id\").split(DELIMITER)})\n",
    "        filepaths = DELIMITER.join({f.strip() for a in attrs if a.get(\"filepath\") for f in a.get(\"filepath\").split(DELIMITER)})\n",
    "        grouped[name] = {\n",
    "                \"name\": name,\n",
    "                \"type\": t,\n",
    "                \"description\": descriptions,\n",
    "                \"source_id\": source_ids,\n",
    "                \"filepath\": filepaths\n",
    "            }\n",
    "        # If only one type, flatten the structure\n",
    "        #grouped[name] = [v for v in types.values()]\n",
    "    grouped = list(grouped.values())\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b4a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = StoragePaths(\n",
    "    documents_db=\"test_graph.db\",\n",
    "    chunks_db=\"test_index\",\n",
    "    graph_db=\"test_vectors\",\n",
    "    chroma_chunks=\"test_chroma_chunks\",\n",
    "    chroma_entities=\"test_chroma_entities\",\n",
    "    chroma_relations=\"test_chroma_relations\"\n",
    ")\n",
    "storage = Storage(paths)\n",
    "storage.init()\n",
    "storage.upsert_nodes(nodes[-5:])\n",
    "grouped = group_nodes(storage, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080e795b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Transformer Architecture',\n",
       "  'type': 'TECHNIQUE',\n",
       "  'description': 'Revolutionary AI model architecture introduced by Vaswani et al. in 2017 with attention mechanism and parallel processing capabilities||Research team that introduced the transformer model in 2017, revolutionizing machine learning||Core component of transformer architecture that allows models to focus on relevant parts of input sequence regardless of position',\n",
       "  'source_id': 'ce3e73a2-7d1a-4111-b374-c4388c0b966d||ce3e7-7d1a-4111-b374-c4388c0b966d||91c96a29-dc84-45a8-8e09-15645c8a8c02',\n",
       "  'filepath': 'ai_transformers_overview.pdf||ai_transformersverview.pdf'},\n",
       " {'name': 'Recurrent Neural Networks',\n",
       "  'type': 'CONCEPT',\n",
       "  'description': 'Traditional neural network architecture that processes sequences sequentially, limiting long-range dependency capture',\n",
       "  'source_id': '91c96a29-dc84-45a8-8e09-15645c8a8c02',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Multi-Head Attention',\n",
       "  'type': 'TECHNIQUE',\n",
       "  'description': 'Transformer component that enables diverse representation learning through multiple attention mechanisms',\n",
       "  'source_id': 'bb95f0a9-bc63-4962-bce6-e9966c7d2c92',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Positional Encoding',\n",
       "  'type': 'TECHNIQUE',\n",
       "  'description': 'Method used in transformers to preserve sequence order information during parallel processing',\n",
       "  'source_id': 'bb95f0a9-bc63-4962-bce6-e9966c7d2c92',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Natural Language Processing',\n",
       "  'type': 'DOMAIN',\n",
       "  'description': 'Field of AI where transformers have become the foundation for state-of-the-art models',\n",
       "  'source_id': '4ae9ba1d-ea8b-4d1c-b768-425d767576de',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Computer Vision',\n",
       "  'type': 'DOMAIN',\n",
       "  'description': 'AI domain where transformers demonstrate remarkable versatility and performance improvements',\n",
       "  'source_id': '4ae9ba1d-ea8b-4d1c-b768-425d767576de',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Machine Learning Revolution',\n",
       "  'type': 'CONCEPT',\n",
       "  'description': 'Transformation in ML field driven by transformer models through attention mechanisms and parallel processing',\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Long-Range Dependencies',\n",
       "  'type': 'CONCEPT',\n",
       "  'description': 'Relationships between distant elements in sequences that transformers can capture more efficiently than RNNs',\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'name': 'Sarah Johnson',\n",
       "  'type': 'PERSON',\n",
       "  'description': 'Product Manager attending the weekly team meeting on January 15, 2025',\n",
       "  'source_id': 'b95c346b-1802-41cd-96de-d8a5826fa200',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Development Team',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'description': 'Cross-functional team including Product Manager, Developer, UX Designer, Data Scientist, and QA Engineer',\n",
       "  'source_id': 'b95c346b-1802-41cd-96de-d8a5826fa200',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Sprint Review',\n",
       "  'type': 'PROCESS',\n",
       "  'description': 'Team completed 8 out of 10 planned user stories with successful performance improvements implementation',\n",
       "  'source_id': '750a0cb7-d488-4226-a45c-9a56811162d7',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Performance Improvements',\n",
       "  'type': 'DELIVERABLE',\n",
       "  'description': 'Successfully implemented enhancements to system performance during the current sprint',\n",
       "  'source_id': '750a0cb7-d488-4226-a45c-9a56811162d7',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Database Migration',\n",
       "  'type': 'TASK',\n",
       "  'description': 'Critical project blocker delayed pending infrastructure team approval',\n",
       "  'source_id': 'f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Third-Party API Integration',\n",
       "  'type': 'TASK',\n",
       "  'description': 'Development work requiring security review before implementation can proceed',\n",
       "  'source_id': 'f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'User Authentication Improvements',\n",
       "  'type': 'PRIORITY',\n",
       "  'description': 'Upcoming focus area for the development team to enhance system security',\n",
       "  'source_id': '3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Q1 Security Audit',\n",
       "  'type': 'MILESTONE',\n",
       "  'description': 'Upcoming security assessment that the team needs to prepare for',\n",
       "  'source_id': '3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Mike Chen',\n",
       "  'type': 'PERSON',\n",
       "  'description': 'Lead Developer responsible for completing API documentation by Wednesday',\n",
       "  'source_id': '46d45855-4286-48b9-93e2-b538905f0222',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'API Documentation',\n",
       "  'type': 'DELIVERABLE',\n",
       "  'description': 'Technical documentation task assigned to Mike Chen with Wednesday deadline',\n",
       "  'source_id': '46d45855-4286-48b9-93e2-b538905f0222',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'name': 'Chocolate Chip Cookies',\n",
       "  'type': 'RECIPE',\n",
       "  'description': 'Classic cookie recipe requiring all-purpose flour, butter, sugars, eggs, vanilla, and chocolate chips',\n",
       "  'source_id': 'dce983d4-888e-4c83-a8d0-fadd7404058b',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Baking Ingredients',\n",
       "  'type': 'CATEGORY',\n",
       "  'description': 'Essential ingredients for cookie making including flour, baking soda, butter, sugars, and chocolate chips',\n",
       "  'source_id': 'dce983d4-888e-4c83-a8d0-fadd7404058b',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Cookie Baking Process',\n",
       "  'type': 'PROCEDURE',\n",
       "  'description': 'Step-by-step instructions for making cookies from mixing ingredients to baking at 375°F for 9-11 minutes',\n",
       "  'source_id': '30b5998f-64e0-4dc4-a995-ba49279ba2a8',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Oven Temperature',\n",
       "  'type': 'PARAMETER',\n",
       "  'description': 'Specific baking temperature of 375°F (190°C) required for proper cookie preparation',\n",
       "  'source_id': '30b5998f-64e0-4dc4-a995-ba49279ba2a8',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Chicken Soup',\n",
       "  'type': 'RECIPE',\n",
       "  'description': 'Homemade soup recipe using whole chicken, vegetables, and egg noodles in a hearty broth',\n",
       "  'source_id': '83655f0c-c6f9-4572-aec3-8a4103d67199',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Soup Vegetables',\n",
       "  'type': 'INGREDIENT_GROUP',\n",
       "  'description': 'Fresh vegetables for soup including carrots, celery, onion, and parsley for flavor and nutrition',\n",
       "  'source_id': '83655f0c-c6f9-4572-aec3-8a4103d67199',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Soup Preparation Method',\n",
       "  'type': 'PROCEDURE',\n",
       "  'description': 'Complete process from simmering whole chicken to adding vegetables, noodles, and seasoning',\n",
       "  'source_id': '70949b44-8d6c-4171-9590-0f7d58f60ea4',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Chicken Broth',\n",
       "  'type': 'BASE_INGREDIENT',\n",
       "  'description': \"Homemade broth created by simmering whole chicken for 1 hour, forming the soup's foundation\",\n",
       "  'source_id': '70949b44-8d6c-4171-9590-0f7d58f60ea4',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Family Recipe Tradition',\n",
       "  'type': 'CONCEPT',\n",
       "  'description': 'Three-generation tradition of passing down cooking knowledge and recipe secrets',\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'name': 'Cooking Secrets',\n",
       "  'type': 'KNOWLEDGE',\n",
       "  'description': 'Traditional cooking tips including using room temperature butter for cookies and homemade broth for soup',\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any\n",
    "from graph.storage import Storage, _normalize_pair\n",
    "\n",
    "# assume DELIMITER is defined (same as in group_nodes)\n",
    "\n",
    "def group_edges(storage: Storage, edges: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Group edges by normalized (source_name, target_name), merge duplicates,\n",
    "    append existing stored edge (if any), and return a flat list.\n",
    "\n",
    "    Input edge schema (expected keys):\n",
    "      - source_name, target_name, weight (optional/number), description, keywords,\n",
    "        source_id, filepath\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(list)\n",
    "\n",
    "    # 1) accumulate incoming edges by normalized pair\n",
    "    for e in edges:\n",
    "        a, b = e[\"source_name\"], e[\"target_name\"]\n",
    "        src, tgt = _normalize_pair(a, b)\n",
    "        grouped[(src, tgt)].append({\n",
    "            \"description\": e.get(\"description\", \"\"),\n",
    "            \"keywords\": DELIMITER.join({k.strip() for k in e.get(\"keywords\", \"\").split(',') if k.strip()}),\n",
    "            \"weight\": float(e.get(\"weight\", 0)),      # may be None or number\n",
    "            \"source_id\": e.get(\"source_id\", \"\"),\n",
    "            \"filepath\": e.get(\"filepath\", \"\")\n",
    "        })\n",
    "\n",
    "    # 2) append existing edges from storage (if present)\n",
    "    for (src, tgt) in list(grouped.keys()):\n",
    "        existing = storage.get_edge(source_name=src, target_name=tgt)\n",
    "        if existing:\n",
    "            grouped[(src, tgt)].append({\n",
    "                \"description\": existing.get(\"description\", \"\"),\n",
    "                \"keywords\": existing.get(\"keywords\", \"\"),\n",
    "                \"weight\": existing.get(\"weight\", None),\n",
    "                \"source_id\": existing.get(\"source_id\", \"\"),\n",
    "                \"filepath\": existing.get(\"filepath\", \"\")\n",
    "            })\n",
    "\n",
    "    # 3) collapse each pair's attrs into one merged record\n",
    "    merged = []\n",
    "    for (src, tgt), attrs in grouped.items():\n",
    "        descriptions = DELIMITER.join({d.strip() for a in attrs if a.get(\"description\") for d in a[\"description\"].split(DELIMITER)})\n",
    "        keywords     = DELIMITER.join({k.strip() for a in attrs if a.get(\"keywords\") for k in a[\"keywords\"].split(DELIMITER) if k.strip()})\n",
    "        weights      = sum([a[\"weight\"]  for a in attrs if a.get(\"weight\") is not None])\n",
    "        source_ids   = DELIMITER.join({a[\"source_id\"]    for a in attrs if a.get(\"source_id\")})\n",
    "        filepaths    = DELIMITER.join({a[\"filepath\"]     for a in attrs if a.get(\"filepath\")})\n",
    "\n",
    "        merged.append({\n",
    "            \"source_name\": src,\n",
    "            \"target_name\": tgt,\n",
    "            \"description\": descriptions,\n",
    "            \"keywords\": keywords,\n",
    "            \"weight\": weights,\n",
    "            \"source_id\": source_ids,\n",
    "            \"filepath\": filepaths\n",
    "        })\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f104652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_name': 'Self-Attention Mechanism',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Transformer architecture was introduced by Vaswani et al. in 2017||Self-attention mechanism is the core component of transformer architecture',\n",
       "  'keywords': 'authorship||architecture||component||core||introduction||research',\n",
       "  'weight': 1.85,\n",
       "  'source_id': '91c96a29-dc84-45a8-8e09-15645c8a8c02||ce3e73a2-7d1a-4111-b374-c4388c0b966d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Multi-Head Attention',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Multi-head attention is a key component of transformer architecture',\n",
       "  'keywords': 'component||attention||multiple',\n",
       "  'weight': 0.9,\n",
       "  'source_id': 'bb95f0a9-bc63-4962-bce6-e9966c7d2c92',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Multi-Head Attention',\n",
       "  'target_name': 'Self-Attention Mechanism',\n",
       "  'description': 'Multi-head attention extends self-attention mechanism with multiple attention heads',\n",
       "  'keywords': 'multiple||extension||attention',\n",
       "  'weight': 0.85,\n",
       "  'source_id': 'bb95f0a9-bc63-4962-bce6-e9966c7d2c92',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Positional Encoding',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Positional encoding preserves sequence order in transformer architecture',\n",
       "  'keywords': 'position||order||sequence',\n",
       "  'weight': 0.85,\n",
       "  'source_id': 'bb95f0a9-bc63-4962-bce6-e9966c7d2c92',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Recurrent Neural Networks',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'RNNs are contrasted with transformers as traditional sequential processing approach',\n",
       "  'keywords': 'traditional||contrast||sequential',\n",
       "  'weight': 0.7,\n",
       "  'source_id': '91c96a29-dc84-45a8-8e09-15645c8a8c02',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Long-Range Dependencies',\n",
       "  'target_name': 'Recurrent Neural Networks',\n",
       "  'description': 'RNNs have limitations in capturing long-range dependencies',\n",
       "  'keywords': 'limitation||sequential||capture',\n",
       "  'weight': 0.8,\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Long-Range Dependencies',\n",
       "  'target_name': 'Self-Attention Mechanism',\n",
       "  'description': 'Self-attention mechanism efficiently captures long-range dependencies',\n",
       "  'keywords': 'attention||capture||efficient',\n",
       "  'weight': 0.9,\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Natural Language Processing',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Transformers are foundational for state-of-the-art NLP models',\n",
       "  'keywords': 'foundation||application||state-of-the-art',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '4ae9ba1d-ea8b-4d1c-b768-425d767576de',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Computer Vision',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Transformers demonstrate versatility and performance in computer vision',\n",
       "  'keywords': 'application||versatility||performance',\n",
       "  'weight': 0.8,\n",
       "  'source_id': '4ae9ba1d-ea8b-4d1c-b768-425d767576de',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Machine Learning Revolution',\n",
       "  'target_name': 'Transformer Architecture',\n",
       "  'description': 'Transformer architecture drives the machine learning revolution',\n",
       "  'keywords': 'revolution||transformation||paradigm',\n",
       "  'weight': 0.95,\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Machine Learning Revolution',\n",
       "  'target_name': 'Self-Attention Mechanism',\n",
       "  'description': 'Self-attention mechanism is a key driver of the ML revolution',\n",
       "  'keywords': 'attention||driver||breakthrough',\n",
       "  'weight': 0.85,\n",
       "  'source_id': 'a8ce29a9-1f26-435d-8d1f-dfd96368af8d',\n",
       "  'filepath': 'ai_transformers_overview.pdf'},\n",
       " {'source_name': 'Development Team',\n",
       "  'target_name': 'Sarah Johnson',\n",
       "  'description': 'Sarah Johnson is the Product Manager in the development team',\n",
       "  'keywords': 'team member||leadership||product manager',\n",
       "  'weight': 0.9,\n",
       "  'source_id': 'b95c346b-1802-41cd-96de-d8a5826fa200',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Development Team',\n",
       "  'target_name': 'Mike Chen',\n",
       "  'description': 'Mike Chen is the Lead Developer in the development team',\n",
       "  'keywords': 'technical||team member||lead developer',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '46d45855-4286-48b9-93e2-b538905f0222',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Development Team',\n",
       "  'target_name': 'Sprint Review',\n",
       "  'description': 'Development team conducted sprint review of completed work',\n",
       "  'keywords': 'process||completion||review',\n",
       "  'weight': 0.85,\n",
       "  'source_id': '750a0cb7-d488-4226-a45c-9a56811162d7',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Performance Improvements',\n",
       "  'target_name': 'Sprint Review',\n",
       "  'description': 'Performance improvements were successfully implemented during the sprint',\n",
       "  'keywords': 'implementation||success||deliverable',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '750a0cb7-d488-4226-a45c-9a56811162d7',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Database Migration',\n",
       "  'target_name': 'Development Team',\n",
       "  'description': 'Database migration is a critical task for the development team',\n",
       "  'keywords': 'infrastructure||critical||blocker',\n",
       "  'weight': 0.8,\n",
       "  'source_id': 'f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Development Team',\n",
       "  'target_name': 'Third-Party API Integration',\n",
       "  'description': 'Third-party API integration requires development work and security review',\n",
       "  'keywords': 'integration||security||review',\n",
       "  'weight': 0.8,\n",
       "  'source_id': 'f3b5c5b4-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Development Team',\n",
       "  'target_name': 'User Authentication Improvements',\n",
       "  'description': 'User authentication improvements are upcoming focus for the development team',\n",
       "  'keywords': 'priority||security||focus',\n",
       "  'weight': 0.85,\n",
       "  'source_id': '3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Q1 Security Audit',\n",
       "  'target_name': 'User Authentication Improvements',\n",
       "  'description': 'User authentication improvements are needed for Q1 security audit preparation',\n",
       "  'keywords': 'audit||preparation||security',\n",
       "  'weight': 0.8,\n",
       "  'source_id': '3c9f5c5b-5c5e-4c5b-8c5b-5c5b5c5b5c5b',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'API Documentation',\n",
       "  'target_name': 'Mike Chen',\n",
       "  'description': 'Mike Chen is responsible for completing API documentation by Wednesday',\n",
       "  'keywords': 'deadline||responsibility||documentation',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '46d45855-4286-48b9-93e2-b538905f0222',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'API Documentation',\n",
       "  'target_name': 'Third-Party API Integration',\n",
       "  'description': 'API documentation is related to third-party API integration work',\n",
       "  'keywords': 'technical||integration||documentation',\n",
       "  'weight': 0.8,\n",
       "  'source_id': '46d45855-4286-48b9-93e2-b538905f0222',\n",
       "  'filepath': 'weekly_team_meeting_2025_01_15.txt'},\n",
       " {'source_name': 'Baking Ingredients',\n",
       "  'target_name': 'Chocolate Chip Cookies',\n",
       "  'description': 'Chocolate chip cookies recipe requires specific baking ingredients',\n",
       "  'keywords': 'recipe||baking||ingredients',\n",
       "  'weight': 0.9,\n",
       "  'source_id': 'dce983d4-888e-4c83-a8d0-fadd7404058b',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chocolate Chip Cookies',\n",
       "  'target_name': 'Cookie Baking Process',\n",
       "  'description': 'Cookie baking process describes how to make chocolate chip cookies',\n",
       "  'keywords': 'process||instructions||procedure',\n",
       "  'weight': 0.95,\n",
       "  'source_id': '30b5998f-64e0-4dc4-a995-ba49279ba2a8',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Cookie Baking Process',\n",
       "  'target_name': 'Oven Temperature',\n",
       "  'description': 'Cookie baking process requires specific oven temperature of 375°F',\n",
       "  'keywords': 'temperature||baking||requirement',\n",
       "  'weight': 0.85,\n",
       "  'source_id': '30b5998f-64e0-4dc4-a995-ba49279ba2a8',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Soup',\n",
       "  'target_name': 'Soup Vegetables',\n",
       "  'description': 'Chicken soup recipe uses fresh vegetables for flavor and nutrition',\n",
       "  'keywords': 'vegetables||ingredients||nutrition',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '83655f0c-c6f9-4572-aec3-8a4103d67199',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Soup',\n",
       "  'target_name': 'Soup Preparation Method',\n",
       "  'description': 'Soup preparation method describes how to make chicken soup',\n",
       "  'keywords': 'preparation||instructions||method',\n",
       "  'weight': 0.95,\n",
       "  'source_id': '70949b44-8d6c-4171-9590-0f7d58f60ea4',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Broth',\n",
       "  'target_name': 'Soup Preparation Method',\n",
       "  'description': 'Chicken broth is created through the soup preparation method',\n",
       "  'keywords': 'foundation||simmering||broth',\n",
       "  'weight': 0.9,\n",
       "  'source_id': '70949b44-8d6c-4171-9590-0f7d58f60ea4',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Broth',\n",
       "  'target_name': 'Chicken Soup',\n",
       "  'description': 'Chicken broth forms the foundation of chicken soup',\n",
       "  'keywords': 'foundation||soup||base',\n",
       "  'weight': 0.95,\n",
       "  'source_id': '70949b44-8d6c-4171-9590-0f7d58f60ea4',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chocolate Chip Cookies',\n",
       "  'target_name': 'Family Recipe Tradition',\n",
       "  'description': 'Chocolate chip cookies are part of three-generation family recipe tradition',\n",
       "  'keywords': 'tradition, family, heritage||tradition||family||heritage',\n",
       "  'weight': 1.6,\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Soup',\n",
       "  'target_name': 'Family Recipe Tradition',\n",
       "  'description': 'Chicken soup is part of three-generation family recipe tradition',\n",
       "  'keywords': 'tradition, family, heritage||tradition||family||heritage',\n",
       "  'weight': 1.6,\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Cooking Secrets',\n",
       "  'target_name': 'Family Recipe Tradition',\n",
       "  'description': 'Cooking secrets are part of the family recipe tradition knowledge',\n",
       "  'keywords': 'tradition||knowledge||secrets, knowledge, tradition||secrets',\n",
       "  'weight': 1.8,\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Cookie Baking Process',\n",
       "  'target_name': 'Cooking Secrets',\n",
       "  'description': 'Cooking secrets include tips for cookie baking like using room temperature butter',\n",
       "  'keywords': 'tips, butter, technique||tips||butter||technique',\n",
       "  'weight': 1.4,\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'},\n",
       " {'source_name': 'Chicken Broth',\n",
       "  'target_name': 'Cooking Secrets',\n",
       "  'description': 'Cooking secrets include using homemade broth for better soup',\n",
       "  'keywords': 'homemade||homemade, quality, technique||quality||technique',\n",
       "  'weight': 1.4,\n",
       "  'source_id': '8de720dd-3311-475d-9c5b-bcabd28a3c1e',\n",
       "  'filepath': 'grandmas_recipes.md'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = StoragePaths(\n",
    "    documents_db=\"test_graph.db\",\n",
    "    chunks_db=\"test_index\",\n",
    "    graph_db=\"test_vectors\",\n",
    "    chroma_chunks=\"test_chroma_chunks\",\n",
    "    chroma_entities=\"test_chroma_entities\",\n",
    "    chroma_relations=\"test_chroma_relations\"\n",
    ")\n",
    "storage = Storage(paths)\n",
    "storage.init()\n",
    "storage.upsert_edges(edges[-5:])\n",
    "grouped = group_edges(storage, edges)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6c9a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transformer architecture, introduced by Vaswani et al. in 2017, has significantly impacted artificial intelligence by using self-attention mechanisms to process sequences in parallel. This approach enables transformers to efficiently manage long-range dependencies, overcoming the limitations of traditional recurrent neural networks (RNNs) that process sequences sequentially.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from graph.llm import llm_summarize_text\n",
    "\n",
    "text = \"\"\"The transformer architecture, introduced by Vaswani et al. in 2017, has revolutionized the field of artificial intelligence. Unlike traditional recurrent neural networks (RNNs) that process sequences sequentially, transformers leverage self-attention mechanisms to capture relationships between all elements in a sequence simultaneously. This parallel processing capability allows transformers to efficiently handle long-range dependencies, which RNNs often struggle with.\"\"\"\n",
    "\n",
    "summary = llm_summarize_text(to_summarize=text, language=\"English\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c767e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The transformer architecture, introduced by Vaswani et al. in 2017, has significantly impacted artificial intelligence by using self-attention mechanisms to process sequences in parallel. This approach enables transformers to efficiently manage long-range dependencies, overcoming the limitations of traditional recurrent neural networks (RNNs) that process sequences sequentially.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a986e01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6df198",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Note: There are two email addresses listed between my application form and my resume. I can be reached at both of them without issue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbf686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note There are two email addresses listed between my application form and my resume. I can be reached at both of them without issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove non non alphanumeric characters except punctuation\n",
    "import re\n",
    "cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d643d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
